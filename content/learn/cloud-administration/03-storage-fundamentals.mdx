---
title: "Storage Fundamentals"
description: Master S3, EBS, EFS, and cloud storage strategies for different workloads.
---

AWS storage services are grouped into three categories: file storage, block storage, and object storage. 
Block storage in the cloud is analogous to direct-attached storage (DAS) or a storage area network (SAN).
File storage systems are often supported with a network-attached storage (NAS) server.
In file storage, data is stored as files in a hierarchy, Each file has metadata such as file name, file size, and the date the file was created. The file also has a path, for example, computer/Application_files/Cat_photos/cats-03.png. When you need to retrieve a file, your system can use the path to find it in the file hierarchy. File storage is ideal when you require centralized access to files that must be easily shared and managed by multiple host computers. Typically, this storage is mounted onto multiple hosts, and requires file locking and integration with existing file system communication protocols.. 
In block storage, data is stored in fixed-size blocks i.e Disks Drives. File storage treats files as a singular unit, but block storage splits files into fixed-size chunks of data called blocks that have their own addresses. Each block is an individual piece of data storage. Because each block is addressable, blocks can be retrieved efficiently. Think of block storage as a more direct route to access the data. When data is requested, the addresses are used by the storage system to organize the blocks in the correct order to form a complete file to present back to the requestor. Besides the address, no additional metadata is associated with each block. If you want to change one character in a file, you just change the block, or the piece of the file, that contains the character. This ease of access is why block storage solutions are fast and use less bandwidth.
In object storage, files are stored as objects in buckets. Objects, much like files, are treated as a single, distinct unit of data when stored. However, unlike file storage, these objects are stored in a bucket using a flat structure, meaning there are no folders, directories, or complex hierarchies. Each object contains a unique identifier. This identifier, along with any additional metadata, is bundled with the data and stored., Changing just one character in an object is more difficult than with block storage. When you want to change one character in an object, the entire object must be updated. Used for Data Archiving and Backup/Recovery.

### STORAGE

1.  An INSTANCE STORE provides temporary block-level storage for an Amazon EC2 instance. An instance store is disk storage that is physically attached to the host computer for an EC2 instance, and therefore has the same lifespan as the instance. When the instance is terminated, you lose any data in the instance store. When you launch an EC2 instance/VM, depending on the type of the EC2 instance you launched, it might provide you with local storage called instance store volumes. These volumes are physically attached to the host, your EC2 instances running on top of. And you can write to it just like a normal hard drive. The catch here is that since this volume is attached to the underlying physical host, if you stop or terminate your EC2 instance, all data written to the instance store volume will be deleted. The reason for this, is that if you start your instance from a stop state, it's likely that EC2 instance will start up on another host. A host where that volume does not exist. Remember EC2 instances are virtual machines, and therefore the underlying host can change between stopping and starting an instance. Because of this ephemeral or temporary nature of Instance Storage volumes, they are useful in situations where you can lose the data being written to the drive. Such as temporary files, scratch data, and data that can be easily recreated without consequence

2.  ELASTIC BLOCK STORE EBS, you can create virtual hard drives, that we call EBS volumes, that you can attach to your EC2 instances. These are separate drives from the local instance store volumes, and they aren't tied directly to the host that you're EC2 is running on. This means, that the data that you write to an EBS volume can persist between stops and starts of an EC2 instance. With ELASTIC BLOCK STORE EBS, you can create virtual hard drives, that we call EBS volumes, that you can attach to your EC2 instances. These are separate drives from the local instance store volumes, and they aren't tied directly to the host that you're EC2 is running on. This means, that the data that you write to an EBS volume can persist between stops and starts of an EC2 instance. EBS volumes act similarly to external drives in more than one way i.e Detachable, Distinct, Size-Limited, 1-to-1 connection, Multi-Attach feature. Amazon EBS multi-attach feature that permits Provisioned IOPS SSD (io1 or io2) volumes to be attached to multiple EC2 instances at one time. This feature is not available for all instance types, and all instances must be in the same Availability Zone
EBS volumes come in all different sizes and types. How this works, is you define the size, type and configurations of the volume you need. Provision the volume, and then attach it to your EC2 instance. From there, you can configure your application to write to the volume and you're good to go. If you stop and then start the EC2 instance, the data in the volume remains. An Amazon EBS volume stores data in a single Availability Zone. To attach an Amazon EC2 instance to an EBS volume, both the Amazon EC2 instance and the EBS volume must reside within the same Availability Zone. Since the use case for EBS volumes is to have a hard drive that is persistent, that your applications can write to, it's probably important that you back that data up. EBS allows you to take incremental backups of your data called snapshots. It's very important that you take regular snapshots of your EBS volumes This way, if a drive ever becomes corrupted, you haven't lost your data. And you can restore that data from a snapshot. An EBS SNAPSHOT is an INCREMENTAL BACKUP. This means that the first backup taken of a volume copies all the data. For subsequent backups, only the blocks of data that have changed since the most recent snapshot are saved.
Azure Disk storage, or Azure managed disks, are block-level storage volumes managed by Azure for use with Azure VMs. Conceptually, they’re the same as a physical disk, but they’re virtualized – offering greater resiliency and availability than a physical disk. With managed disks, all you have to do is provision the disk, and Azure will take care of the rest.

3.  AMAZON SIMPLE STORAGE SERVICE S3 BUCKET is a service that provides object-level storage. Amazon S3 stores data as objects in buckets. When you upload a file to Amazon S3, you can set permissions to control visibility and access to it. Amazon S3 provides several security management features: IAM policies, S3 bucket policies, and encryption to develop and implement your own security policies. When IAM policies are attached to your resources (buckets and objects) or IAM users, groups, and roles, the policies define which actions they can perform. Access policies that you attach to your resources are referred to as resource-based policies and access policies attached to users in your account are called user-based policies. Like IAM policies, S3 bucket policies are defined in a JSON format. Unlike IAM policies, which are attached to resources and users, S3 bucket policies can only be attached to S3 buckets. The policy that is placed on the bucket applies to every object in that bucket. S3 bucket policies specify what actions are allowed or denied on the bucket. If you have used an online storage service to back up the data from your local machine, you most likely have used a service similar to Amazon S3. When you store an object in a bucket, the combination of a bucket name, key, and version ID uniquely identifies the object. When you create a bucket, you specify, at the very minimum, two details: the bucket name and the AWS Region that you want the bucket to reside in. You can also use the Amazon S3 versioning feature to track changes to your objects over time. S3 is your backup strategy. Plus the cost savings is substantial overrunning the same storage load on EBS. With the additional advantage of being serverless, no Amazon EC2 instances are needed. With Amazon S3, you pay only for what you use. You can choose from a range of Amazon S3 storage classes to select a fit for your business and cost needs. When selecting an Amazon S3 storage class, consider these two factors:
*   How often you plan to retrieve your data
*   How available you need your data to be
Amazon S3 versioning. Versioning keeps multiple versions of a single object in the same bucket. This preserves old versions of an object without using different names, which helps with object recovery from accidental deletions, accidental overwrites, or application failures. If you enable versioning for a bucket, Amazon S3 automatically generates a unique version ID for the object. By using versioning-enabled buckets, you can recover objects from accidental deletion or overwrite. Buckets can be in one of three states Unversioned(Default), Versioning-Enabled, Versioning-Suspended. The versioning state applies to all objects in the bucket. Storage costs are incurred for all objects in your bucket, including all versions. To reduce your Amazon S3 bill, you might want to delete previous versions of your objects when they are no longer needed or define a lifecycle configuration for an object or group of objects, you can choose to automate between two types of actions: transition and expiration.
    Transition actions define when objects should transition to another storage class.
    Expiration actions define when objects expire and should be permanently deleted.
Azure BLOBS: A massively scalable object store for text and binary data.
Also includes support for big data analytics through Data Lake Storage Gen2. Azure Storage offers different access tiers for your BLOB storage, helping you store object data in the most cost-effective manner. The available access tiers include:
    Hot access tier: Optimized for storing data that is accessed frequently (for example, images for your website).
    Cool access tier: Optimized for data that is infrequently accessed and stored for at least 30 days (for example, invoices for your customers).
    Cold access tier: Optimized for storing data that is infrequently accessed and stored for at least 90 days.
    Archive access tier: Appropriate for data that is rarely accessed and stored for at least 180 days, with flexible latency requirements (for example, long-term backups). You created a storage account, added a container to the storage account, and then uploaded blobs (files) to your container. Then you changed the access policy(ACL) so you could access your file from the internet.

4.  AWS ELASTIC FILE SYSTEM is a scalable file system used with AWS Cloud services and on-premises resources. In file storage, multiple clients (such as users, applications, servers, and so on) can access data that is stored in shared file folders. In this approach, a storage server uses block storage with a local file system to organize files. Clients access data through file paths. Compared to block storage and object storage, file storage is ideal for use cases in which a large number of services and resources need to access the same data at the same time. As you add and remove files, Amazon EFS grows and shrinks automatically. It can scale on demand to petabytes without disrupting applications. Amazon EFS is a regional service. It stores data in and across multiple Availability Zones. The duplicate storage enables you to access data concurrently from all the Availability Zones in the Region where a file system is located. Additionally, on-premises servers can access Amazon EFS using AWS Direct Connect.
AWS Elastic File System (Amazon EFS) is a set-and-forget file system that automatically grows and shrinks as you add and remove files. There is no need for provisioning or managing storage capacity and performance. Amazon EFS can be used with AWS compute services and on-premises resources. You can connect tens, hundreds, and even thousands of compute instances to an Amazon EFS file system at the same time, and Amazon EFS can provide consistent performance to each compute instance. With the Amazon EFS simple web interface, you can create and configure file systems quickly without any minimum fee or setup cost. You pay only for the storage used and you can choose from a range of storage classes designed to fit your use case.  Amazon FSx provides native compatibility with third-party file systems. You can choose from NetApp ONTAP, OpenZFS, Windows File Server, and Lustre. With Amazon FSx, you don't need to worry about managing file servers and storage

Azure FILES: Managed file shares for cloud or on-premises deployments.
Azure File storage offers fully managed file shares in the cloud that are accessible via the industry standard Server Message Block (SMB) or Network File System (NFS) protocols. Azure Files file shares can be mounted concurrently by cloud or on-premises deployments. SMB Azure file shares are accessible from Windows, Linux, and macOS clients. NFS Azure Files shares are accessible from Linux or macOS clients. Additionally, SMB Azure Files shares can be cached on Windows Servers with Azure File Sync for fast access near where the data is being used.

Azure QUEUES: A messaging store for reliable messaging between application components.
Azure Queue storage is a service for storing large numbers of messages. Once stored, you can access the messages from anywhere in the world via authenticated calls using HTTP or HTTPS. A queue can contain as many messages as your storage account has room for (potentially millions). Each individual message can be up to 64 KB in size. Queues are commonly used to create a backlog of work to process asynchronously. Queue storage can be combined with compute functions like Azure Functions to take an action when a message is received

### AZURE

| Type | Supported services | Redundancy Options | Usage |
| --- | --- | --- | --- |
| Standard general-purpose v2 | Blob Storage (including Data Lake Storage), Queue Storage, Table Storage, and Azure Files | LRS, GRS, RA-GRS, ZRS, GZRS, RA-GZRS | Standard storage account type for blobs, file shares, queues, and tables. Recommended for most scenarios using Azure Storage. If you want support for network file system (NFS) in Azure Files, use the premium file shares account type. |
| Premium block blobs | Blob Storage (including Data Lake Storage) | LRS, ZRS | Premium storage account type for block blobs and append blobs. Recommended for scenarios with high transaction rates or that use smaller objects or require consistently low storage latency. |
| Premium file shares | Azure Files | LRS, ZRS | Premium storage account type for file shares only. Recommended for enterprise or high-performance scale applications. Use this account type if you want a storage account that supports both Server Message Block (SMB) and NFS file shares. |
| Premium page blobs | Page blobs only | LRS | Premium storage account type for page blobs only. |

An AZURE storage account provides a unique namespace for your Azure Storage data that's accessible from anywhere in the world over HTTP or HTTPS. Data in this account is secure, highly available, durable, and massively scalable. The type of account determines the storage services and redundancy options and has an impact on the use cases. 
Below is a list of redundancy options that will be covered later in this module:

    Locally redundant storage (LRS)
    Geo-redundant storage (GRS)
    Read-access geo-redundant storage (RA-GRS)
    Zone-redundant storage (ZRS)
    Geo-zone-redundant storage (GZRS)
    Read-access geo-zone-redundant storage (RA-GZRS)

One of the benefits of using an Azure Storage Account is having a unique namespace in Azure for your data. In order to do this, every storage account in Azure must have a unique-in-Azure account name. No two storage accounts can have the same name. This supports the ability to have a unique, accessible namespace in Azure -> 3-24Xters in Length with Numbers and Lowercase only. The combination of the account name and the Azure Storage service endpoint forms the endpoints for your storage account.

## Storage Redundancy

Azure Storage always stores multiple copies of your data so that it's protected from planned and unplanned events such as transient hardware failures, network or power outages, and natural disasters. Redundancy ensures that your storage account meets its availability and durability targets even in the face of failures.

When deciding which redundancy option is best for your scenario, consider the tradeoffs between lower costs and higher availability. The factors that help determine which redundancy option you should choose include:

    How your data is replicated in the primary region.
    Whether your data is replicated to a second region that is geographically distant to the primary region, to protect against regional disasters.
    Whether your application requires read access to the replicated data in the secondary region if the primary region becomes unavailable.

### Azure Storage Redundancy Options with Typical Read Availability SLAs

| Redundancy Option | Redundancy in Primary Region | Redundancy in Secondary Region | Read Access in Secondary Region? | Typical Read Availability SLA (Primary Region) | Typical Read Availability SLA (Secondary Region) |
| --- | --- | --- | --- | --- | --- |
| Locally-redundant storage (LRS) | 3 synchronous copies within one physical location (data center) | None | N/A | >= 99.9% | N/A |
| Zone-redundant storage (ZRS) | 3 synchronous copies across three Availability Zones | None | N/A | >= 99.9% | N/A |
| Geo-redundant storage (GRS) | 3 synchronous copies within one physical location (LRS) in the Primary Region & Geo-Replicated in aSecondary Region | 3 asynchronous copies within one physical location (LRS) | No (unless failover occurs) | >= 99.9% | N/A (Read access not guaranteed) |
| Geo-zone-redundant storage (GZRS) | 3 synchronous copies across three Availability Zones (ZRS) | 3 asynchronous copies within one physical location (LRS) | No (unless failover occurs) | >= 99.9% | N/A (Read access not guaranteed) |
| Read-access GRS (RA-GRS) | 3 synchronous copies within one physical location (LRS) | 3 asynchronous copies within one physical location (LRS) | Yes | >= 99.9% | >= 99.99% |
| Read-access GZRS (RA-GZRS) | 3 synchronous copies across three Availability Zones (ZRS) | 3 asynchronous copies within one physical location (LRS) | Yes | >= 99.9% | >= 99.99% |

#### Important Notes on SLAs:
Read Availability vs. Durability: The SLAs listed above primarily refer to read availability. Azure Storage also offers extremely high durability SLAs (designed to protect against data loss), often cited as 11 nines for LRS/ZRS and 16 nines for GRS/GZRS variants.
Typical Values: These percentages represent the typical minimum guaranteed uptime for read operations under the SLA. Always refer to the official Azure SLA documentation for the most current and precise figures, as they can vary slightly based on storage type (Blob, File, Queue, Table) and specific configurations.
Secondary Region Read SLA: Note that only the RA-GRS and RA-GZRS options provide a specific, higher SLA for read access to the secondary region endpoint. For standard GRS/GZRS, read access to the secondary is only possible after Microsoft initiates a failover.
## Key Takeaways

- S3/Blob Storage for object storage; EBS for block storage
- Match storage tier (hot, cool, archive) to access frequency
- Implement lifecycle policies for automated tiering and cost optimization
- Use encryption at rest and in transit for sensitive data
